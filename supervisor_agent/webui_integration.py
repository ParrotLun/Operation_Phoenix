"""
Open WebUI æ•´åˆæ¨¡çµ„
æä¾›ä¸²æµä»‹é¢å’Œå°è©±è¨˜æ†¶ç®¡ç†
"""
from typing import Iterator, Dict, Any, Optional
from langchain_core.messages import HumanMessage
from supervisor_agent.agent import app
from supervisor_agent.utils.memory_manager import ConversationMemoryManager, SessionManager


class OpenWebUIAdapter:
    """
    Open WebUI é©é…å™¨

    åŠŸèƒ½ï¼š
    1. ä¸²æµè¼¸å‡ºï¼ˆyield chunksï¼‰
    2. å°è©±è¨˜æ†¶ç®¡ç†
    3. Session ç®¡ç†
    4. State æŒä¹…åŒ–æ”¯æ´
    """

    def __init__(
        self,
        enable_memory: bool = True,
        max_recent_messages: int = 4,
        compression_threshold: int = 10
    ):
        """
        åˆå§‹åŒ–é©é…å™¨

        Args:
            enable_memory: æ˜¯å¦å•Ÿç”¨å°è©±è¨˜æ†¶ç®¡ç†
            max_recent_messages: ä¿ç•™æœ€è¿‘å¹¾æ¢å®Œæ•´è¨Šæ¯
            compression_threshold: è¶…éå¹¾æ¢è¨Šæ¯é–‹å§‹å£“ç¸®
        """
        self.graph = app
        self.enable_memory = enable_memory

        if enable_memory:
            self.memory_manager = ConversationMemoryManager(
                max_recent_messages=max_recent_messages,
                compression_threshold=compression_threshold
            )
        else:
            self.memory_manager = None

        # ç°¡å–®çš„ session storageï¼ˆç”Ÿç”¢ç’°å¢ƒæ‡‰ä½¿ç”¨ Redis æˆ–è³‡æ–™åº«ï¼‰
        self.session_states = {}

    def stream_response(
        self,
        data: Dict[str, Any],
        previous_state: Optional[Dict[str, Any]] = None
    ) -> Iterator[str]:
        """
        Open WebUI ä¸²æµä»‹é¢

        Args:
            data: {
                "message": str,           # ä½¿ç”¨è€…è¨Šæ¯
                "session_id": str,        # å¯é¸çš„ session ID
                "stream_mode": str        # å¯é¸ï¼Œé è¨­ "updates"
            }
            previous_state: ä¸Šä¸€è¼ªå°è©±çš„ stateï¼ˆå¯é¸ï¼‰

        Yields:
            æ ¼å¼åŒ–çš„ä¸²æµè¼¸å‡º
        """
        message = data.get("message", "")
        session_id = data.get("session_id")
        stream_mode = data.get("stream_mode", "updates")

        # æº–å‚™åˆå§‹ state
        initial_state = self._prepare_initial_state(
            message=message,
            session_id=session_id,
            previous_state=previous_state
        )

        # ä¸²æµåŸ·è¡Œ
        try:
            for chunk in self.graph.stream(initial_state, stream_mode=stream_mode):
                yield from self._format_chunk(chunk)

            # å„²å­˜ stateï¼ˆå¦‚æœå•Ÿç”¨ memoryï¼‰
            if self.enable_memory and session_id:
                # é€™è£¡æ‡‰è©²å„²å­˜å®Œæ•´çš„ final state
                # åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ï¼Œæ‡‰è©²å¾ graph å–å¾— final state
                pass

        except Exception as e:
            yield f"\nâŒ Error: {str(e)}\n\n"

    def _prepare_initial_state(
        self,
        message: str,
        session_id: Optional[str],
        previous_state: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        æº–å‚™åˆå§‹ state

        è™•ç†ï¼š
        1. Session ID
        2. å°è©±è¨˜æ†¶å£“ç¸®
        3. ä¿ç•™é‡è¦ state æ¬„ä½
        """
        # æ–°è¨Šæ¯
        new_message = HumanMessage(content=message)

        # æª¢æŸ¥æ˜¯å¦ç‚ºé€£çºŒå°è©±
        if previous_state and self.enable_memory:
            # å¾ä¸Šä¸€è¼ª state æ¢å¾©
            if self.memory_manager.has_conversation_context(previous_state):
                # å£“ç¸®æ­·å²è¨Šæ¯
                optimized_messages = self.memory_manager.prepare_context_for_llm(
                    previous_state
                )

                # çµ„åˆæ–° state
                return {
                    "messages": optimized_messages + [new_message],
                    "conversation_id": previous_state.get("conversation_id"),
                    # ä¿ç•™é‡è¦çš„ state æ¬„ä½
                    "latest_datcom": previous_state.get("latest_datcom"),
                    "parsed_file_data": previous_state.get("parsed_file_data"),
                    "file_content": previous_state.get("file_content")
                }

        # æ–°å°è©±
        if not session_id:
            session_id = SessionManager.generate_session_id()

        return {
            "messages": [new_message],
            "conversation_id": session_id
        }

    def _format_chunk(self, chunk: Dict[str, Any]) -> Iterator[str]:
        """
        æ ¼å¼åŒ– chunk ç‚º Open WebUI è¼¸å‡º

        Args:
            chunk: LangGraph stream chunk

        Yields:
            æ ¼å¼åŒ–çš„å­—ä¸²
        """
        if "agent" not in chunk:
            return

        # å–å¾— agent çš„ messages
        agent_data = chunk["agent"]
        messages = agent_data.get("messages", [])

        for msg in messages:
            content = getattr(msg, 'content', '')
            if content:
                # ç›´æ¥è¼¸å‡ºå…§å®¹ï¼ˆåŒ…å« <think> æ¨™ç±¤ï¼‰
                yield f"{content}\n\n"

    def get_session_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """
        å–å¾— session state

        Args:
            session_id: Session ID

        Returns:
            State dict æˆ– None
        """
        return self.session_states.get(session_id)

    def save_session_state(self, session_id: str, state: Dict[str, Any]):
        """
        å„²å­˜ session state

        Args:
            session_id: Session ID
            state: State dict
        """
        self.session_states[session_id] = state

    def clear_session(self, session_id: str):
        """
        æ¸…é™¤ session

        Args:
            session_id: Session ID
        """
        if session_id in self.session_states:
            del self.session_states[session_id]


class ThinkTagFormatter:
    """
    <think> æ¨™ç±¤æ ¼å¼åŒ–å™¨
    ç”¨æ–¼ç¾åŒ–è¼¸å‡º
    """

    @staticmethod
    def format_thinking(content: str) -> str:
        """
        æ ¼å¼åŒ–åŒ…å« <think> æ¨™ç±¤çš„å…§å®¹

        å°‡ <think>...</think> è½‰æ›ç‚º Markdown æ ¼å¼çš„æ€è€ƒå€å¡Š
        """
        import re

        # åŒ¹é… <think>...</think>
        think_pattern = r'<think>(.*?)</think>'

        def replace_think(match):
            thinking_content = match.group(1).strip()
            return f"\nğŸ’­ **æ€è€ƒä¸­...**\n```thinking\n{thinking_content}\n```\n\n"

        # æ›¿æ›æ‰€æœ‰ <think> æ¨™ç±¤
        formatted = re.sub(think_pattern, replace_think, content, flags=re.DOTALL)

        return formatted


# ==================== ä½¿ç”¨ç¯„ä¾‹ ====================

"""
# åŸºæœ¬ä½¿ç”¨ï¼ˆç„¡è¨˜æ†¶ï¼‰
adapter = OpenWebUIAdapter(enable_memory=False)

for chunk in adapter.stream_response({"message": "è«‹è®€å– msg.txt"}):
    print(chunk, end='', flush=True)


# é€²éšä½¿ç”¨ï¼ˆæœ‰è¨˜æ†¶ï¼‰
adapter = OpenWebUIAdapter(
    enable_memory=True,
    max_recent_messages=4,
    compression_threshold=10
)

# ç¬¬ä¸€è¼ªå°è©±
session_id = "user_123_session"
data1 = {
    "message": "è«‹è®€å– msg.txt ä¸¦ç”¢ç”Ÿ DATCOM æª”æ¡ˆ",
    "session_id": session_id
}

for chunk in adapter.stream_response(data1):
    print(chunk, end='', flush=True)

# å„²å­˜ stateï¼ˆç°¡åŒ–ç‰ˆï¼Œå¯¦éš›æ‡‰å¾ graph å–å¾—ï¼‰
# adapter.save_session_state(session_id, final_state)

# ç¬¬äºŒè¼ªå°è©±ï¼ˆé€£çºŒï¼‰
previous_state = adapter.get_session_state(session_id)
data2 = {
    "message": "å‰›æ‰çš„ç¿¼å‹æ˜¯ä»€éº¼ï¼Ÿ",
    "session_id": session_id
}

for chunk in adapter.stream_response(data2, previous_state=previous_state):
    print(chunk, end='', flush=True)


# ä½¿ç”¨ <think> æ¨™ç±¤æ ¼å¼åŒ–
formatter = ThinkTagFormatter()
content_with_think = '''<think>
User wants DATCOM file
Need to route to datcom_tool_agent
</think>
å¥½çš„ï¼Œæˆ‘ä¾†ç”¢ç”Ÿ DATCOM æª”æ¡ˆ'''

formatted = formatter.format_thinking(content_with_think)
print(formatted)

# è¼¸å‡ºï¼š
# ğŸ’­ **æ€è€ƒä¸­...**
# ```thinking
# User wants DATCOM file
# Need to route to datcom_tool_agent
# ```
#
# å¥½çš„ï¼Œæˆ‘ä¾†ç”¢ç”Ÿ DATCOM æª”æ¡ˆ
"""
